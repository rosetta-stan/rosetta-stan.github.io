---
title: "Stan Usage"
author: "Breck Baldwin"
date: "8/8/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This document tracks Stan and Stan ecosystem usage over time. 

#CRAN downloads

```{r}
library(cranlogs)
library(ggplot2)
library(dplyr)
library(lubridate)
library(httr)
library(jsonlite)
library(stringr)
library(R.cache)
library(ggrepel)

packages <- c('rstan','rstanarm','brms','tensorflow','lme4','BART','Rcpp','ggplot2')

dls <- cran_downloads(
  packages = packages, 
  from ="2016-01-01",
  to = "2020-09-30"
)

mls <- dls %>% mutate(month=floor_date(date,"monthly")) %>% 
  group_by(month,package)  %>% #?? order matters for month/package??
  summarize(monthly_downloads=sum(count))

# mls data check
 mls_val = (mls %>% filter(package=='rstanarm') %>%
            filter(month=='2018-02-01'))$monthly_downloads 
 
 dls_val = sum(cran_downloads(packages = c('rstanarm'), 
               from ="2018-02-01", to = "2018-02-28")$count)
 
 if (mls_val != dls_val) {
   stop(sprintf(paste("Problems with data, expect computed monthly total",        "mls_val=%d and more simply computed monthly total dls_val=%d to be equal"),
   mls_val, dls_val))
 }

#plot <- ggplot() + geom_line(data=mls,
#                  aes(x=month, y=monthly_downloads, color=package))

label_month <- max(mls$month)
mls_label <- mls %>% 
  mutate(label=if_else(month == label_month, 
                       as.character(package),NA_character_))

plot1 <- ggplot(data=mls_label,
                aes(x=month, y=monthly_downloads, color=package,
                    group=package)) +
         geom_line()

log_plot1 <- plot1 + scale_y_continuous(breaks=c(0,100,1000,10000,100000,1000000), 
                     trans = scales::log_trans())

log_plot1_display <- log_plot1 +
  geom_label_repel(aes(label = label), na.rm = TRUE) +
         scale_color_discrete(guide = FALSE)

log_plot1_2030_scale <- log_plot1 +   
            xlim(as.Date('2016-01-01'),as.Date('2030-01-31'))

log_plot1_2030_slopes_display <- log_plot1_2030_scale +
  geom_smooth(method='lm',formula=y~x, fullrange=TRUE) +
  geom_label_repel(aes(label = label), na.rm = TRUE) +
         scale_color_discrete(guide = FALSE)


```


```{r message=FALSE, warning=FALSE}
print(plot1)
```


```{r message=FALSE, warning=FALSE}
print(log_plot1)
```

#Stan references at scholar.google.com. 

Do you have a licence for SCOPUS? That can get you a version of the output from google scholar but in a csv file.
Andrew Gelman11:46 AM
https://statmodeling.stat.columbia.edu/2019/04/29/we-shouldntve-called-it-stan-i-shouldve-listened-to-bob-and-hadley/
Lu Zhang11:52 AM
rjags r2jags nimble 

```{r}
library('httr')
library('jsonlite')
library('stringr')
library('R.cache')
library('tidyr')
library('ggplot2')
library(dplyr)
library(lubridate)
library(ggrepel)
library(redux)


get_results <-function(url) {
  key <- list(url)
  data <- loadCache(key=key)
  if (!is.null(data)) {
    cat(paste("\nhitting cache for",url))
    return(data)
  }
  cat(paste("\ncache miss, querying:",url,"\n"))
  random_wait <- abs(rnorm(1,5,5))
  cat(paste("\nWaiting",random_wait,"seconds to be nice to webserver\n"))
  Sys.sleep(random_wait)
  result <- GET(url)
  saveCache(result,key=key)
  return(result)
}

query_builder <- function(and='', or='', not='', phrase='', loc='any', start='', end='') {
  url <- ''
  if (or == '' && not == '' && phrase=='' && loc=='any') { #simple query
    url <- paste("https://scholar.google.com/scholar?",
                 "q=",str_replace_all(and,'\\s+','+'),
                 "&hl=en&as_sdt=0%2C33&as_ylo=",start,
                 "&as_yhi=",end,sep="")
  } else { #advanced query
    url <- paste("https://scholar.google.com/scholar?as_q=",str_replace_all(and,'\\s+','+'),
                 "&as_epq=",str_replace_all(phrase,'\\s+','+'),
                 "&as_oq=",str_replace_all(or,'\\s+','+'),
                 "&as_eq=",str_replace_all(not,'\\s+','+'),
                 "&as_occt=",str_replace_all(loc,'\\s+','+'), #title/any for where to search
                 "&as_sauthors=",
                 "&as_publication=",
                 "&as_ylo=",start,
                 "&as_yhi=",end,
                 "&hl=en",
                 "&as_sdt=0%2C33", #  don't know what this element is
                 sep="")
  }
  return(url)
}


year_start <- 2012
year_end <- 2020
date_queried <- '2020-08-15'

# extrapolate to full year
day_count_current_year <- as.numeric(as.Date(date_queried) - as.Date('2020-01-01'))
extrapolation_partial_year = 365/day_count_current_year

# truncate 2020 to partial year 
end_date_in_decimal <- 2020 + day_count_current_year/365

years <- c(as.double(year_start:(year_end -1)),end_date_in_decimal)
years <- year_start:year_end
df <- data.frame(years)
df_cumul <- data.frame(years)

pkg_query <- c('mc-stan.org', 'rstan bayes', 'rstanarm','pymc3',
               'mc-stan.org', 'rstan bayes', 'rstanarm','pymc3',
               '','','')



#keras overgenerates, needs classifier

pkg_query <- c('rstan', 'pymc3','pystan',
               '','','',
               '','','')


pkg_query <- c('stan','tensorflow','pytorch','thanos',
               'mc-stan.org', '','','',
               '','','','')


pkg_query <- c('machine learning interpretability', 'black box','machine learning','deep learning','deep learning black box','"black box" ai',
               '','','','','','',
               '','','','','','')

pkg_query <- c('machine learning','','')

pkg_query <- c('rstan', 'pymc3','pystan',
               '','','',
               '','','')

pkg_query <- c('pymc3','stan','rstan', 'tensorflow','bayesian*','pytorch',
               '','mc-stan.org', '','','','',
               '','','','','mc-stan.org+rstan+rstanarm+pymc3','')

#pkg_query <- c('pymc3','stan','rstan', 'rstanarm', #'tensorflow','bayesian*','pytorch',
#               '','mc-stan.org', '','','','','',
#               '','','','','','mc-stan.org+rstan+rstanarm+pymc3','')


#  pkg_query <- c('pymc3', 'pymc', 'rstan', 'pystan', 'pymc2', 'pymc4', 'pymc*',
#               'pymc3', 'pymc', 'rstan', 'pystan', 'pymc2', 'pymc4', '',
#               '', '', '', '' , '', '', 'pymc+pymc2+pymc3+pymc4')

#pkg_query <- c('pymc3', 'rstan', 'pystan', 'pymc*',
#               'pymc3', 'rstan', 'pystan', '',
#               '',      '',      '',       'pymc+pymc2+pymc3+pymc4')


pkg_query <- c('pymc3','stan','rstan', 'tensorflow','bayesian*','pytorch',
               '','mc-stan.org', '','','','',
               '','','','','mc-stan.org+rstan+rstanarm+pymc3','')

pkg_query_m <- matrix(pkg_query,ncol=3)

for (i in 1:nrow(pkg_query_m) ) {
  package = pkg_query_m[i,1]
  and_query = pkg_query_m[i,2]
  or_query = pkg_query_m[i,3]
  if (and_query == '' && or_query == '') { #use package name if no and/or
    and_query = package
  }
  year_counts = c()
  for (year in year_start:year_end) {
    url <- query_builder(and=and_query, or=or_query, start=year, end=year)
    result <- get_results(url) #  Cached get calls with waits
    result_text <- content(result,'text')
    count <- NA
    if (!is.na(str_match(result_text,"did not match any articles")[1,1])) {
      count = 0
    } else { # '2 results (0.02 sec)', 'About 3,454 results' match first instance of
      #print(result_text)
      count_string = str_match(result_text,"(About )?([\\d,]+) result(s)?")[1,3]
      count = as.numeric(str_remove_all(count_string,","))
    }
    year_counts <- c(year_counts,count)
  }
  df[package] <- year_counts
  df_cumul[package] <- cumsum(year_counts)
}

df[nrow(df),2:ncol(df)] <- df[nrow(df),2:ncol(df)] * extrapolation_partial_year


# trim the scale on the graph to be correct for Aug 8 so we don't have to interpolate but only works for cumulative


df_long <- gather(df,package,yr_count,
                  pkg_query_m[1,1]:pkg_query_m[nrow(pkg_query_m),1])

df_long_label <- df_long %>% 
  mutate(label=if_else(years == max(years), 
                       as.character(package),NA_character_))

plot2 <- ggplot(data=df_long_label,aes(x=years,y=yr_count,group=package, color=package)) + 
  geom_point() +
  geom_line() +
  geom_label_repel(aes(label = label),
                   na.rm = TRUE) +
  scale_color_discrete(guide = FALSE)


log_plot2 <- plot2 + scale_y_continuous(breaks=c(0,10,100,1000,10000),
                                        trans = scales::log_trans()) +
             scale_x_continuous(breaks=c(2010,2012,2014,2016,2018,2020)) +
             geom_point(shape=20)



bar_plot2 <- ggplot(data=df_long_label,aes(x=years,y=yr_count,group=package, fill=package)) + geom_col(position = position_dodge(preserve = 'single')) 
log_bar_plot2 <- bar_plot2 +
                 scale_x_continuous(breaks=c(2010,2012,2014,2016,2018,2020)) +
                 scale_y_continuous(breaks=c(0,10,100,1000,10000),
                                                                                            trans = scales::log_trans())
bar_plot3 <- ggplot(data=df_long_label,aes(x=reorder(years,package),y=yr_count, color=package)) + geom_col(position = "dodge")

#  =====
start_col <- pkg_query_m[1,1]
end_col <- pkg_query_m[nrow(pkg_query_m),1]
df_cumul_long <- gather(df_cumul, key=package, value=yr_count_cumul, 
                        all_of(start_col):all_of(end_col))

df_cumul_long_label <- df_cumul_long %>% 
  mutate(label=if_else(years == max(years), 
                       as.character(package),NA_character_))

plot_cumlative <- ggplot(data=df_cumul_long_label,aes(x=years,y=yr_count_cumul,group=package, color=package)) + 
  geom_line() +
  geom_label_repel(aes(label = label),
                   na.rm = TRUE) +
  scale_color_discrete(guide = FALSE)

log_plot_cumulative <- plot_cumlative + scale_y_continuous(breaks=c(0,2,20,150,1000),
                                    trans = scales::log_trans())

```

```{r message=FALSE, warning=FALSE}
print(plot2) 
```

```{r message=FALSE, warning=FALSE}
print(plot_cumulative)
```


# Scopus

```{r}

    
```

